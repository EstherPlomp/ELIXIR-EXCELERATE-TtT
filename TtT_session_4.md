# ELIXIR â€“ EXCELERATE Train-the Trainer subtask

## Session 4: Assessment and feedback in training

* [Introduction to assessment and feedback in training](#introduction)
    * [Assessment timeline - when and why to assess](#timeline)
* [Pre-course assessment - Diagnostic questionnaires](#diagnostic)
* [Feedback to learners](#feedback)
    * [Summative and formative assessment](#summative)
* [Feedback from learners](#feedbackfrom)
    * [Systematic Feedback;](#systematic)
* [Short term feedback - assessment of training quality, participant and instructor performance.](#short)
* [Long term post-course feedback.](#short)
* [Dealing with (bad) feedback.](#dealing)
* [Extra - Going deeper on Training Evaluation](#extra1)
* [Extra - 50 classroom assessment techniques (CATs) by Angelo & Cross](#extra2)

<a name="introduction"></a>
## Introduction to assessment and feedback in training

>### Activity (individual) - Challenge 1: what kind of feedback/assessment do you know as a learner or use as a trainer?
> 
> * What type of assessment did you undertake as a learner or trainer?
> * What was its purpose in your opinion? 
> * Was it useful to your learning or teaching? 
> 
> Write at least one example and discuss it with us.

<a name="timeline"></a>
### Assessment timeline - when and why to assess

1. Pre-course assessment (before the course) - verify the target audience of the course
2. Preventive assessment (beginning of the course) - final adjustments of the course to the reality of the participants
3. Formative assessment (during the course) - pilot in real time if learning is taking place
4. Summative assessment (right after the course) - measure and evaluate the knowledge and skills acquired
5. Strategic evaluation (after the course, long time after the course) - measure the adequacy, quality and impact of the course  

<a name="diagnostic"></a>
## Pre-course assessment - Diagnostic questionnaires
Pre-course assessment are useful tools for teachers to get an idea of where the learners and the group of learners stand at the beginning of a course. This is very helpful to setup realistic learning objectives, to meet expectations of learners and to adapt the course content to fill gaps identified in the diagnostic questionnaire and avoid spending time in things that are not necessary. Diagnostic questionnaires can be anonymous or not. Anonymous questionnaires allow to have an idea of the level of knowledge of the whole group of learners. An example of a diagnostic anonymous questionnaire for a session on PPI resources is giving [here](https://docs.google.com/forms/d/1d1yOiNaBdcyGgxaaRqP47b3K06zvYQS0CT8eu0I0d1E/edit#). And [here](https://docs.google.com/forms/d/1d1yOiNaBdcyGgxaaRqP47b3K06zvYQS0CT8eu0I0d1E/viewanalytics) you can see how the responses look like.

Non-anonymous and personal questionnaires allow to find out if the learner has a necessary pre-required knowledge, and in the negative case indicate an appropriate teaching choice to palliate this lack. 

<a name="feedback"></a>
## Feedback to learners

<a name="summative"></a>
### Summative and formative assessment

*Summative assessment*. An exam or a test at the end of a course is an example of summative assessment. Summative assessment is aimed at evaluating learners' performance at the end of teaching (this could be at the end of a topic, a session, or at the end of the entire course). This is the most frequent type of assessment occurring in schools and universities and usually includes grading. It is less frequent in training.

*Formative assessment*. Formative assessment takes place **during** teaching and learning. Its purpose is to help both instructors and learners to become aware of what the focus should be. 

Formative assessment can be used to collect information about learners'

- prior knowledge
- mental models
- level of mastery of the topic at hand
- goals and objectives
- frequent mistakes 

And can help understand

- which knowledge gaps need to be filled before moving on
- whether their mental models are correct
- if the level of mastery is sufficient according to the course's learning objectives and outcomes
- if learners goals and objectives are aligned to the course's goals and objectives 
- which types of mistakes need special attention

**Self-assessment** may be a problem because students may not be able to accurately assess their abilities. Generally, people tend to overestimate their knowledge and skills. Accuracy improves when the response options are clear and tied to speciic concepts or behaviours. Example in Amborse et al. (2010) Appendix A. 

In particular, formative assessment can be used to: 

#### 1) activate and explore prior knowledge 
#### 2) to promote peer instruction and content delivery
- You can use an anonymous diagnostic questionnaire as described [below](#diagnostic).

#### 3) to practice retrieval
..... (see Small Teaching)

#### 4) to stimulate reflection and prepare learners' brain for learning

#### 5) to highlight learners' weaknesses and difficulties and therefore to set the pace of the following teaching

#### 6) to help learners understand what they have to focus on 

Formative assessment can be done in many different ways:

- Asking questions to learners and getting responses orally;
- Asking them to describe the strategy they would adopt to solve a problem;
- Asking them to solve a problem in groups, or individually but in front of the class;
- Using brainstorming and discussions;
- Providing diagnostic questionnaires;
- Providing MCQs with distractors.

In the following, we report the seven assumptions on which the CATs (Course Assessment Techniques) are based and five suggestions to use them fruitfully and effectively: 

>From [Angelo and Cross](./docs/angelo_and_cross_assessment_techniques.pdf):
>
> Classroom Assessment is based on these assumptions:
> 
1. The quality of student learning is directly, although not exclusively, related to the quality of teaching. 
2. To improve their effectiveness teachers need first to make their goals and objectives explicit and then to get specific, comprehensible feedback on the extent to which they are achieving those goals and objectives.
3. To improve their learning, students need to receive appropriate and focused feedback early and often; they also need to learn how to assess their own learning.
4. The type of assessment most likely to improve teaching and learning is that conducted by faculty to answer questions they themselves have formulated in response to issues or problems in their own teaching.
5. Systematic inquiry and intellectual challenge are powerful sources of motivation, growth, and renewal for college teachers, and Classroom Assessment can provide such challenge.

>
> Five suggestions for a successful start:
1. If a Classroom Assessment Techniques does not appeal to your intuition and professional judgement as a teacher, don't use it.
2. Don't make Classroom Assessment into a self-inflicted chore or burden.
3. Don't ask your students to use any Classroom Assessment Technique you haven't previously tried on yourself.
4. Allow for more time than you think you will need to carry out and respond to the assessment.
5. Make sure to "close the loop." Let students know what you learn from their feedback and how you and they can use that information to improve learning.


<a name="self"></a>
### Self-assessment, self-confidence and usage independence

In active learning environments, learners are so involved in the learning process that they often loose consciousness about their accumulated knowledge and its level of operational value. Learning by doing catches them in the process, so they often forget about assessing it.

In good quality training, instructors make efforts to keep the interaction loop closed. As facilitators, they can give steering contributions to this build-up.

At carefully chosen times, it may be useful to intervene and stimulate self assessment (see how to, under instant feedback below). Self assessment helps to regain such consciousness. Learners verify that they can do things that they could not do by themselves before, or at least that the need for external aid is lowering. This can be seen as a work-out process towards gaining independence or mastery in a subject matter. The conscious learner feels "empowered". It is up to the instructor to moderate and keep this empowerment within reasonable limits. Learners that are not feeling empowered often find it by comparing their experience with their peers. Dialogues between learners will naturally occur, but can also be stimulated by reflective exercises (such as in Software and Data Carpentry). The instructor will learn to adapt the level of intervention to each situation, keeping in mind that the learner is the focus of the learning process, and that the instructor/learner relationship is the cornerstone of learning as a stimulated human activity.


<a name="feedbackfrom"></a>
## Feedback from learners

Feedback from learners is aimed at:

- assessing learner reactions to teachers and teaching thus providing context-specific feedback that can improve teaching within a particular course;
- assessing learner reactions to class activities, assignments, and materials thus giving instructors information that will help them improve their course materials and assignments;
- assessing learner reactions course organisational aspects, thus providing the organiser information that will help him or her to improve the course organisation.

<a name="systematic"></a>
### Systematic immediate feedback

In a training course, getting feedback at the end of the event is necessary, as the participants may (should) have developed encompassing, integrated views. However, it is vastly insufficient. Questioning participants frequently during training provision is rich with information and has very interesting effects. But when should this happen? And how can it be induced so that, as a drug, has as many positive effects  and as low adverse effects as possible?

When? Ideally at natural breakpoints such as ending an exercise, shifting to a different subject and right after a wrap-up session.

How? It should be very focused and expedite in execution. The instructor should think of a clearly stated question that has a binary (Yes/no) or garaded (0-5) response. Ideally the isntructor should write the question and display it, ensuring that everybody knows what the question is at the same time and is aware of what the answering method is. Then, the instructor collects the answers and record them in a tally. 

This is **Instant Feedback**. 


### Carpentry assessing practices

Notice that the Carpentry teaching practices quoted in [session 2](./TtT-session2.md) - Sticky notes; Minutes cards; One-up, one-down - are forms of Instant Feedback.

### Instant Feedback: benefits worth noticing 

* For the LEARNER. Carefully implemented instant feedback obliges the learner to introspect, to answer himself first (do I really know this? How easy it it for me to do this by myself?). With this, it becomes clear that he is made aware of his own progress and this is the smartest way to gain self-confidence. When questioned at the end-of the course questionnaire, he is much more able to make encompassing self assessments
* For the INSTRUCTOR. Multiple ways of checking if what has just been done was effective, as a result of the quality of the question. Useful assessment of the quality of the materials and the performance of the instructor. A way of identifying learners that may be dragging behind and may need more attention. A way of identifying learners that are getting ahead of the others in the group, and can become more active, receive harder assignments, help their colleagues, etc. A way to judge whether the pace of training delivery is correctly chosen for the audience.


<a name="short"></a>
## Short term feedback - assessment of training quality, participant and instructor performance through a questionnaire

<a name="long"></a>
## Long term post-course feedback

Long term assessments (over 6 months after a course) are rather difficult. First because learners move jobs/cities frequently and become more difficult to contact with. Secondly because they forget, as all of us do. In this case they forget what worked for them as hidden details. Those may matter because what we are looking for, here, is the assessment of impacts that endure.

Interviewing former course participants would be a possibility but it requires a lot of time. Sending them short questions by e-mail has worked  with a yeald of about 30%, so unless you are tarining at least several hundreds of people it is likely that you end-up with a very small number of answers. Currently we see some home in the usage of social networks to collect valuable data.

Critical appraisals often happen is casual conversations. One should take notes to record them.

Example: Pedro Fernandes, Pooja Jain, Catarina Moita Training Experimental Biologists
in Bioinformatics, Adv Bioinformatics. 2012;2012:672749. doi:
10.1155/2012/672749. Epub 2012 Jan 31. (Open Access)


<a name="extra1"></a>
## Extra - Going deeper on Training Evaluation

#### The Kirkpatrick Model

- Level 1: Reaction
- 
The degree to which participants find the training favorable, engaging and relevant to their jobs

- Level 2: Learning
- 
The degree to which participants acquire the intended knowledge, skills, attitude, confidence and commitment based on their participation in the training

- Level 3: Behavior
- 
The degree to which participants apply what they learned during training when they are back on the job

- Level 4: Results
- 
The degree to which targeted outcomes occur as a result of the training and the support and accountability package

This model has been revised and expanded several times, see for example:

http://www.kirkpatrickpartners.com/OurPhilosophy/TheNewWorldKirkpatrickModel/tabid/303/Default.aspx

Applying the Kirkpatrick model and its variants is not easy. One needs to be very careful in checking pre-requisites, assumptions and options in the measurement methods.

You may like to read an article about applying Kirkpatrick's methods. https://www.mindtools.com/pages/article/kirkpatrick.htm


<a name="extra2"></a>
## Extra - 50 classroom assessment techniques (CATs) by Angelo & Cross

[Here] (./docs/angelo_and_cross_50_cats.pdf) you can find the **50 CATS by Angelo and Cross**. These are fifty assessment techinques grouped by purpose which can be used in teaching and in training. Some of them better apply to university semester courses, or high school classes, wheras some may turn out to be also useful in training courses/sessions. They are fully described and discussed in the book ""Classroom assessment techinques: A handbook for college teachers" (1993) by the same authors. A description of the book written by the authors can be found [here](angelo_and_cross_assessment_techniques.pdf). 
